\section{Convolutions on graphs (draft that will be splitted in multiple sections)}

Defining a convolution on graphs is a challenging problem. Obviously, the underlying structure determined by a graph is not necessarily isomorphic to a set onto which the convolution is already defined. 

Related works: moura, spectral convolution with laplacian.

Our construction of a generalized convolution is as follow: we first analyze the convolution on domains onto which it is already defined. Then we search for domains onto which the definitions can be easily extended. Finally we discuss generalization to irregular domains and analyze whether the properties of the regular convolution are lost and to what extent.

A convolution may comprise the following properties: bilinear, equivariant with respect to a certain class of isomorphism.

We shall first study classes of graphs onto which the convolution can be naturally defined before generalizing.

*Convolution without the edges

*Convolution on grids

*Convolution on lattice-regular graphs

*Convolution on product graphs

*Convolution on linear combination of circulant graphs

\todo{brief outline}

\subsection{Analysis of the classical convolution operator}

In this subsection, we are exposing a few properties of the classical convolution that a generalization to graphs would likely try to preserve. For now let's consider a graph $G$ agnostically of its edges \ie $G \cong V$ is just the set of its vertices.

Let's recall what is a transformation, and how it acts on signals.

\begin{definition}\textbf{Transformation}\\
A \emph{transformation} $f: V \rightarrow V$ is a function with same domain and codomain. The set of transformations is denoted $\Phi(V)$. The set of bijective transformations is denoted $\Phi^*(V) \subset \Phi(V)$.

In case $f \in \Phi^*(V)$, it can act on $\cs(V)$ through the linear operator $L_f \in \cl(\cs(V))$ defined as:
\begin{gather*}
\forall s \in \cs(V), \forall v \in V, f(s)[v] := L_f s[v] = s[f^{-1}(v)]
\end{gather*}
\ie an entry of a transformed signal is obtained by doing a lookup of the entry of the original signal.

In case $f \notin \Phi^*(V)$, we can still define $L_f \in \cl(\cs(V))$, however we need to linearly aggregate the entries on the fibers:
\begin{gather*}
\forall s \in \cs(V), \forall v \in V, f(s)[v] := L_f s[v] = \agg\{s[u], u \in f^{-1}\{v\}\}
\end{gather*}
where $\agg$ can be for example the sum, the average, or the max, and $\agg(\emptyset) = 0$.
\end{definition}

\subsubsection{Characterization on grid graphs}

Consider an edge-less grid graph \ie $G \cong \bbz^2$. By restriction to compactly supported signals, this case encompass the case of images.

\begin{definition}\textbf{Translation on $\cs(\bbz^2)$}\\
A translation on $\bbz^2$ is defined as a transformation $t \in \Phi^*(\bbz^2)$ such that
\begin{gather*}
\exists (a,b) \in \bbz^2, \forall (x,y) \in \bbz^2, t(x,y) = (x+a,y+b)
\end{gather*}
It also acts on $\cs(\bbz^2)$ with the notation $t_{a,b}$ \ie
\begin{gather*}
\forall s \in \cs(\bbz^2), \forall (x,y) \in \bbz^2, t_{a,b}(s)[x,y] = s[x-a, y-b]
\end{gather*}
For any set $E$, we denote by $\ct(E)$ its translations if they are defined.
\end{definition}

\begin{definition}\textbf{Convolution on $\cs(\bbz^2)$}\\
Recall that the convolution between two signals $s_1$ and $s_2$ over $\bbz^2$ is a binary operator in $\cs(\bbz^2)$ defined as:
\begin{align*}
\forall (a,b) \in \bbz^2, (s_1 * s_2) [a,b] & = \displaystyle \sum_i \sum_j s_1[i,j] \h{2} s_2[a-i, b-j]
\end{align*}
\end{definition}

The next proposition can be seen as a discretization of a classic result in distribution theory.

\begin{proposition}\textbf{Characterization of convolution operators on $\cs(\bbz^2)$}\\
On real-valued signals over $\bbz^2$, the class of linear transformations that are equivariant to translations is exactly the class of convolutive operations \ie
\begin{gather*}
\exists w \in \cs(\bbz^2), f = . \ast w \Leftrightarrow
\begin{cases}
 f \in \cl(\cs(\bbz^2))\\
 \forall t \in \ct(\cs(\bbz^2)), f \circ t = t \circ f
\end{cases}
\end{gather*}
\label{prop:equi}
\end{proposition}

\begin{proof}
The result from left to right is a direct consequence of the definitions:
\begin{align}
\forall s \in \cs(\bbz^2), \forall s' \in \cs(\bbz^2), & \forall (\alpha, \beta) \in \bbr^2,\forall (a,b) \in \bbz^2,\nonumber\\
 %f_w(s)[a,b] & = \displaystyle \sum_i \sum_j s[i,j] \h{2} w[a-i, b-j] \tag{definition}\\
 f_w(\alpha s + \beta s')[a,b] & = \displaystyle \sum_i \sum_j (\alpha s + \beta s')[i,j] \h{2} w[a-i, b-j]\nonumber\\
 & = \alpha f_w(s)[a,b] + \beta f_w(s')[a,b] \tag{linearity}\\
\forall s \in \cs(\bbz^2), \forall (\alpha, \beta) \in \bbz^2, & \forall (a,b) \in \bbz^2,\nonumber\\
f_w \circ t_{\alpha,\beta} (s)[a,b] & = \displaystyle \sum_i \sum_j t_{\alpha,\beta}(s)[i,j] \h{2} w[a-i, b-j]\nonumber\\
 & = \displaystyle \sum_i \sum_j s[i - \alpha,j - \beta] \h{2} w[a-i, b-j]\nonumber\\
 & = \displaystyle \sum_{i'} \sum_{j'} s[i',j'] \h{2} w[a - i' - \alpha, b - j'- \beta]\label{eq:bij}\\
 & = f_w (s)[a - \alpha,b - \beta]\nonumber\\
 & = t_{\alpha,\beta} \circ f_w (s)[a,b] \tag{equivariance}
\end{align}
Now let's prove the result from right to left .

Let $f \in \cl(\cs(\bbz^2))$, $s \in \cs(\bbz^2)$. We suppose that $f$ commutes with translations. Recall that $s$ can be linearly decomposed on the infinite family of dirac signals:
\begin{gather*}
s = \displaystyle \sum_i \sum_j s[i,j] \h{2} \delta_{i,j} \text{, where }
\delta_{i,j}[x,y] = \begin{cases} 1 & \text{if } (x,y) = (i,j)\\ 0 & \text{otherwise} \end{cases}
\end{gather*}
By linearity of $f$ and then equivariance to translations:
\begin{align*}
f(s) & = \displaystyle \sum_i \sum_j s[i,j] \h{2} f(\delta_{i,j})\\
 & = \displaystyle \sum_i \sum_j s[i,j] \h{2} f \circ t_{i,j} (\delta_{0,0})\\
 & = \displaystyle \sum_i \sum_j s[i,j] \h{2} t_{i,j} \circ f (\delta_{0,0})
\end{align*}
By denoting $w = f (\delta_{0,0}) \in \cs(\bbz^2)$, we obtain:
\begin{align}
\forall (a,b) \in \bbz^2, f(s)[a,b] & = \displaystyle \sum_i \sum_j s[i,j] \h{2} t_{i,j}(w)[a,b] \label{eq:conv}\\
 & = \displaystyle \sum_i \sum_j s[i,j] \h{2} w[a-i, b-j] \nonumber\\
\text{\ie } f(s) & = s \ast w \nonumber
\end{align}
\end{proof}

\begin{remark}\textbf{Equivariance property of CNNs}\\
In deep learning, an important argument in favor of CNNs is that convolutional layers are equivariant to translations. Intuitively, that means that a detail of an object in an image should produce the same features independently of its position in the image.
\end{remark}

\begin{remark}\textbf{Lossless superiority of CNNs over MLPs}\\
The converse result, as a consequence of~\propref{prop:equi}, is never mentioned in deep learning literature. However it is also a strong one: it means that layers of CNNs have every translational equivariant functions in their search space, so it implies that the reduction of parameters from an MLP to a CNN is done with strictly no loss of expressivity (provided the objective function is know to bear this property). Besides, it helps the training to search in a much more confined space.
\end{remark}

\subsubsection{Construction on groups}

As \propref{prop:equi} is a complete characterization of convolutions, it can be used to define them \ie convolutive operations can be constructed as the set of linear transformations that are equivariant to translations. However, in the general case where $G$ is not a grid graph, translations are not defined, so that construction needs to be generalized beyond translational equivariances.

\todo{reword sentence below (not exactly true)}
A classic result from group theory is that one sense of this characterization (equivariance) hold for groups of (bijective) transformations, where the group of translations is a particular case. More generally, it also holds for groupoids \citep{weinstein1996groupoids}. The converse sense will be discussed later.

Note that our approach is different than in \citep{cohen2016group}, where the authors define group-equivariant convolutions from an already defined one. On graphs, convolutions aren't already defined. We are studying group convolutions in view of constructing one.

\begin{definition}\textbf{Group convolution I}\\
Let a group $\group$, the group convolution I between two signals $s_1$ and $s_2 \in \cs(\group)$ is defined as:
\begin{align*}
\forall h \in \group, (s_1 \ast_{\I} s_2)[h] & = \displaystyle \sum_{g \in \group} s_1[g] \h{2} s_2[g^{-1}h]%\\
%& = \displaystyle \sum_{ab = h} s_1[a] \h{2} s_2[b]
\end{align*}
provided one of the signals has finite support if $\group$ is not finite.
\label{def:conv1}
\end{definition}

For a graph $\gve$ and a subgroup $\Gamma \subset \Phi^*(V)$, this definition is applicable for $\cs(\Gamma)$, but not for $\cs(V)$ as $V$ is not a group.

Nonetheless, let's assume we can provide $V$ with a group structure by exhibiting an isomorphism $\varphi$ from $\Gamma$ to $V$. Then, the linear morphism $\widetilde\varphi$ from $\cs(\Gamma)$ to $\cs(V)$ defined by $\widetilde\varphi(\delta_g) = \delta_{\varphi(g)}$ is also an isomorphism. Hence, $V$ and $\cs(V)$ would inherit the same inherent structural properties as $\Gamma$ and $\cs(\Gamma)$, in addition of being related in the same way. For notational simplicity, we will use the same symbol $\varphi$ for $\varphi$ and $\widetilde\varphi$ (as done between $f$ and $L_f$). A commutative diagram between the sets is depicted on \figref{fig:iso}.

\begin{figure}[H]
\centering
\begin{tikzcd}%
    \Gamma \arrow{r}{\varphi}  \arrow{d}[swap]{\cs}  & V \arrow{d}{\cs}\\  
    \cs(\Gamma) \arrow{r}[swap]{\varphi}  & \cs(V) 
\end{tikzcd}%
\caption{Commutative diagram between sets}
\label{fig:iso}
\end{figure}

Hence, we can steer the definition of the group convolution from $\cs(\Gamma)$ to $\cs(V)$ as follows:

\begin{definition}\textbf{Group convolution II}\\
Let a subgroup $\Gamma \subset \Phi^*(V)$ such that $V \cong \Gamma$ through an isomorphism $g_v \overset{\varphi}\mapsto v$.
The group convolution II between two signals $s_1$ and $s_2 \in \cs(V)$ is defined as:
\begin{align*}
\forall u \in V, (s_1 \ast_{\II} s_2) [u] & = \displaystyle \sum_{v \in V} s_1[v] \h{2} s_2[\varphi(g_v^{-1}g_u)]\\
& = \displaystyle \sum_{\substack{(a,b) \in V^2 \\ \st g_ag_b=g_u }} s_1[a] \h{2} s_2[b]
\end{align*}
\label{def:conv2}
\end{definition}

\begin{proposition}\textbf{Equivariance to $\varphi(\Gamma)$}\\
With \defref{def:conv2}, convolution operators acting on the right of $\cs(V)$ are equivariant to $\varphi(\Gamma)$ \ie
\begin{gather*}
\exists w \in \cs(V), f = . \ast_{\II} w \Rightarrow \forall v \in V, f \circ \varphi(g_v) = \varphi(g_v) \circ f
\end{gather*}
\label{prop:equi}
\end{proposition}

\begin{proof}
\begin{align*}
\forall s \in \cs(V), \forall u \in V & ,\forall v \in V,\\
(f_w \circ \varphi(g_u)) (s) [v] & = \sum_{\substack{(a,b) \in V^2 \\ \st g_ag_b=g_v }} \varphi(g_u)(s)[a] \h{2} w[b]\\
& = \sum_{\substack{(a,b) \in V^2 \\ \st g_ag_b=g_v }} s[\varphi(g_u)^{-1}(a)] \h{2} w[b]\\
& = \sum_{\substack{(a,b) \in V^2 \\ \st g_{\varphi(g_u)(a)}g_b=g_v }} s[a] \h{2} w[b]\\
\end{align*}
Because $\varphi$ is an isomorphism, its inverse $c \mapsto g_c$ is also an isomorphism and so $g_{\varphi(g_u)(a)}g_b=g_v \Leftrightarrow g_{a}g_b=g_{\varphi(g_u)^{-1}(v)}$. So we have:
\begin{align*}
(f_w \circ \varphi(g_u)) (s) [v] & = \sum_{\substack{(a,b) \in V^2 \\ \st g_{a}g_b=g_{\varphi(g_u)^{-1}(v)} }} s[a] \h{2} w[b]\\
& = s \ast_{\II} w [\varphi(g_u)^{-1}(v)]\\
& = (\varphi(g_u) \circ f_w) (s) [v]
\end{align*}
\end{proof}

\begin{remark}Note that convolution operators of the form $f_w = . \ast_{\I} w$ are also equivariant to $\group$, but the proposition and the proof are omitted as they are similar to the latter.
\end{remark}

In fact, both group convolutions are the same as the latter one borrows the algebraic structure of the first one. Thus we only obtain equivariance to $\varphi(\Gamma)$, which is actually $V$ equipped with the group structure of $\Gamma$ mirrored via $\varphi$. To obtain equivariance to $\Gamma$, we need to take into account the fact that it contains bijective transformations of $V$.

Hence, note that $g \in \Gamma$ can act on both $\Gamma$ through the left multiplication and on $V$ as being an object of $\Phi^{*}(V)$. This ambivalence can be seen on a commutative diagram, see \figref{fig:com}.%, where all arrows except the one labeled with \eqref{eq:P} are always true.

\begin{figure}[H]
\centering
\begin{tikzcd}%
    g_u \arrow{r}{g_v}  \arrow{d}[swap]{\varphi}  & g_vg_u \arrow{d}{\varphi}\\  
    u \arrow{r}{\eqref{eq:P}}[swap]{g_v}  & \varphi(g_vg_u)
\end{tikzcd}%
\caption{Commutative diagram. All arrows except for the one labeled with \ref{eq:P} are always True.}
\label{fig:com}
\end{figure}

With this in mind we obtain the following definitions.

\begin{definition}\textbf{$\varphi$-coherent action}\\
A subgroup $\Gamma \subset \Phi^*(V)$ is said to be \emph{$\varphi$-coherent} if $V \cong \Gamma$ through an isomorphism $g_v \overset{\varphi}\mapsto v$  and if it verifies the property:
\begin{gather*}
\forall v \in V, \forall u \in V, g_v(u) = \varphi(g_vg_u) \tag{P}\label{eq:P}
\end{gather*}
\end{definition}

\begin{remark}
For example, translations on the grid graph, with $\varphi(t_{i,j}) = (i,j)$, are $\varphi$-coherent as $t_{i,j}(a,b) = \varphi(t_{i,j} \circ t_{a,b})$. However, with $\varphi(t_{i,j}) = (-i,-j)$, they would not be $\varphi$-coherent.
\end{remark}

\begin{definition}\textbf{Group convolution III}\\
Let a subgroup $\Gamma \subset \Phi^*(V)$ such that $V \cong \Gamma$ through an isomorphism $g_v \overset{\varphi}\mapsto v$.
The group convolution III between two signals $s_1$ and $s_2 \in \cs(V)$ is defined as:
\begin{align}
s_1 \ast_{\III} s_2 & = \displaystyle \sum_{v \in V} s_1[v] \h{2} g_v(s_2)\nonumber\\
& = \displaystyle \sum_{g \in \Gamma} s_1[\varphi(g)] \h{2} g(s_2) \label{eq:premix}
\end{align}
\label{def:conv3}
\end{definition}

\begin{lemma}\textbf{Relation with group convolution II}\\
$\Gamma \text{ is } \varphi \text{-coherent} \Leftrightarrow \ast_{\II} = \ast_{\III}$
\label{lem:rel}
\end{lemma}

\begin{proof}
\begin{align}
\forall s_1, s_2 & \in \cs(V),\nonumber\\
& s_1 \ast_{\II} s_2 = s_1 \ast_{\III} s_2 \nonumber\\
& \Leftrightarrow \forall u \in V,
\displaystyle \sum_{v \in V} s_1[v] \h{2} s_2[\varphi(g_v^{-1}g_u)] = \displaystyle \sum_{v \in V} s_1[v] \h{2} s_2[g_v^{-1}(u)] \label{eq:free}
\end{align}
Hence, the direct sense is obtained by applying \eqref{eq:P}. 

For the converse, given $u, v \in V$, we first realize \eqref{eq:free} for $s_1 := \delta_v$, obtaining $s_2[\varphi(g_v^{-1}g_u)] = s_2[g_v^{-1}(u)]$, which we then realize for a real signal $s_2$ having no two equal entries, obtaining $\varphi(g_v^{-1}g_u) = g_v^{-1}(u)$. From the latter we finally obtain \eqref{eq:P} with the one-to-one correspondence $v := v^{-1}$, where $v^{-1} = \varphi(g_v^{-1})$ and using the fact that $\varphi$ and $\varphi^{-1}$ are isomorphisms.
\end{proof}

This time, we obtain equivariance to $\Gamma$.

\begin{proposition}\textbf{Equivariance to $\Gamma$}\\
With \defref{def:conv3}, if $\Gamma$ is $\varphi$-coherent, convolution operators acting on the right of $\cs(V)$ are equivariant to $\Gamma$ \ie
\begin{gather*}
\begin{cases}
\Gamma \text{ is } \varphi \text{-coherent}\\
\exists w \in \cs(V), f = . \ast_{\III} w
\end{cases}
\Rightarrow \forall g \in \Gamma, f \circ g = g \circ f
\end{gather*}
\label{prop:equi}
\end{proposition}

\begin{proof}
In the following equations, \eqref{eq:rel} is obtained from \lemref{lem:rel}, \eqref{eq:left} is obtained because left multiplication in a group is an isomorphism, and \eqref{eq:pty} is obtained because of \eqref{eq:P}.
\begin{align}
\forall g \in \Gamma, \forall s \in \cs(V), & \nonumber\\
f_w \circ g (s) & = \displaystyle \sum_{h \in \Gamma} g(s)[\varphi(h)] \h{2} h(w)\label{eq:rel}\\
 & = \displaystyle \sum_{h \in \Gamma} g(s)[\varphi(gh)] \h{2} gh(w)\label{eq:left}\\
 & = \displaystyle \sum_{h \in \Gamma} g(s)[g(\varphi(h))] \h{2} gh(w)\label{eq:pty}\\
 & = \displaystyle \sum_{h \in \Gamma} s[\varphi(h)] \h{2} gh(w)\nonumber\\
\forall g \in \Gamma, \forall s \in \cs(V), & \forall u \in V, \nonumber\\
f_w \circ g (s) [u] & = \displaystyle \sum_{h \in \Gamma} s[\varphi(h)] \h{2} h(w)[g^{-1}(u)]\nonumber\\
& = f_w (s) [g^{-1}(u)]\nonumber\\
& = g \circ f_w (s) [u]\nonumber
\end{align}
\end{proof}

From $\eqref{eq:premix}$, we define a mixed domain convolution \ie that is defined for $r \in \cs(\Gamma)$ and $s \in \cs(V)$, without the need of expliciting the isomorphisms $\varphi$.

\begin{definition}\textbf{Mixed domain convolution}\\
Let a subgroup $\Gamma \subset \Phi^*(V)$ such that $V \cong \Gamma$.
The mixed domain convolution between two signals $r \in \cs(\Gamma)$ and $s \in \cs(V)$ results in a signal $r \ast_{\M} s \in \cs(V)$ and is defined as:
\begin{align*}
\forall u \in V, (r \ast_{\M} s) [u] & = \displaystyle \sum_{g \in \Gamma} r[g] \h{2} g(s)
\end{align*}
\label{def:convm}
\end{definition}

\begin{proposition}\textbf{Relation with group convolution III}\\
$\forall \varphi \in \iso(\Gamma, V), r \ast_{\M} s = \varphi(r) \ast_{\II} s$
\end{proposition}

\begin{proof}
\todo{}
\end{proof}

\begin{proposition}\textbf{Relation with group convolution I}\\
Let $\varphi \in \iso(\Gamma, V)$, we have\\
$r \ast_{\M} s = r \ast_{\I} \varphi^{-1}(s) \Leftrightarrow \Gamma \text{ is } \varphi \text{-coherent}$
\end{proposition}

\begin{proof}
\todo{}
\end{proof}

The direct result is important because it justifies that even without the need of expliciting them, there are underlying isomorphisms $\varphi$ for which the group $\Gamma$ is $\varphi$-coherent.

\todo{introduce edges now}

At this point, there are a two drawbacks: (D1) that $V \cong \Gamma$, (D2) the converse of the characterization doesn't hold. Let's now consider the edge set in our construction and keep these drawbacks in mind.

\subsubsection{Construction on Cayley graphs}

We now consider the class of Cayley (di)graphs~\citep{cayley1878desiderata,wiki:cayley} because the $\varphi$-coherence property \eqref{eq:P} naturally holds on them.

\todo{rewrite and obtain: On a Cayley graph, there is $\varphi$ such that the subgroupoid of transformation that are EC is $\varphi$-coherent (proof on $\cu$ then extended)}

\begin{definition}\textbf{Cayley graph}\\
Let a group $\Gamma$ and one of its generating set $\cu$. The \emph{Cayley graph} generated by $\cu$, is the digraph $\vgve$ such that $V \cong \Gamma$ through $u \overset{\h{9}\varphi^{-1}}{\mapsto} g_u$, and $E$ is such that:
\begin{gather*}
a \sim b \Leftrightarrow \exists u \in \varphi(\cu) \subset V, g_ug_a = g_b
\end{gather*}
\end{definition}

\begin{proposition}
A Cayley graph of group $\Gamma \overset{\varphi}{\cong} V$ is $\varphi$-coherent.
\end{proposition}

\begin{proof}
Let $\cu \subset \Gamma$ the generating set of the Cayley graph.



\todo{}
\end{proof}

We can alleviate (D1) by summing onto the generating set $\cu$ instead of onto~$\Gamma$, which also makes the convolution on Cayley graphs edge-constrained.

\todo{not equivariant unless abelian group}

\begin{definition}\textbf{Cayley graph convolution}\\
\begin{align*}
\forall u \in V, (s_1 \ast s_2) [u] & = \displaystyle \sum_{g \in \cu} s_1[g] \h{2} g(s_2)
\end{align*}
\end{definition}

Conversely, let a graph $\gve$ and a $\varphi$-coherent subgroup $\Gamma \subseteq \Phi^{*}(V)$. Then we can generate a Cayley graphs with a generating set of $\Gamma$, and thus define a Cayley graph convolution. In particular, when transformations of~$\Gamma$ are edge-constrained, that would also be the case for this convolution on $G$, which leads us to study edge-constrained transformations.

\todo{operator and characterization}
\todo{which graph is a Cayley graph ?}

\subsubsection{Construction on graph groupoids}

\todo{work in progress}

On graphs, we notice that the property \eqref{eq:P} can be realized by transformations acting on edges. However, unless the graph is complete, these actions can't be composed everywhere to form another edge constrained action. The algebraic structure that posesses the same kind of properties than a group except that its composition law is not defined everywhere is called a groupoid. The following definitions clarify our discussion.

\begin{definition}\textbf{Groupoid}\\
A groupoid is a set equiped with a closed partial composition law, a unique identity element, and every unique inverses.
\end{definition}

\begin{remark}We use the convention than left and right inverses must be the same.
\end{remark}

\begin{definition}\textbf{Graph groupoid}\\
The \emph{groupoid} $\cp(G)$ of a graph $\gve$ is the set of its paths equiped with:
\begin{enumerate}
\item two maps $\psi$ and $\varphi$ that respectively map a path to its first and last element,
\item a closed partial composition law $gh$ defined if and only if $\psi(g) = \varphi(h)$, which concatenates $g$ behind $h$ and \sout{removes adjacent duplicate vertices} \textcolor{red}{to rewrite},
\item an inverse operator $\h{0}^{-1}$ which maps a path to its reverse,
\item an identity element $\id$ which is the path of length $0$.
\end{enumerate}
\end{definition}

\begin{remark}Recall from \defref{def:path} that a path can't contain adjacent duplicates.
\end{remark}

\begin{remark}Note that even though the composite path $gh$ has elements of $h$ before those of $g$ we write $gh$ instead of $hg$ because we'll need the left operand to act on the right one through functional notation $g(h)$.
\end{remark}

\begin{definition}\textbf{Graph $k$-groupoid}\\
The \emph{$k$-groupoid} $\cp_k(G)$ of a graph $\gve$, for $k \in \bbn^*$, is the groupoid obtained by restricting $\cp(G)$ to paths of length at most $k$ (the definition domain of its composition law is also further restricted by the length of the resulting paths in $\cp(G)$).
\end{definition}

\begin{definition}\textbf{$k$-Groupoid convolution}\\
Let a graph $\gve$. Let a subgroupoid $\Gamma \subseteq \cp_k(G)$. The $k$-groupoid convolution between two signals $s_1$ and $s_2 \in \cs(\Gamma)$ is defined as:
\begin{align*}
\forall h \in \Gamma, (s_1 \ast s_2) [h] & = \displaystyle \sum_{\substack{(a,b) \in \Gamma^2 \\ \st ab=h }} s_1[a] \h{2} s_2[b] \\
& = \displaystyle \sum_{\substack{g \in \Gamma\\ \st \varphi(g) = \varphi(h)}} s_1[g] \h{2} s_2[g^{-1}h]\\
& = \displaystyle \sum_{\substack{g \in \Gamma\\ \st \psi(g) = \psi(h)}} s_1[hg^{-1}] \h{2} s_2[g]
\end{align*}
\label{def:pconv}
\end{definition}

\begin{claim}\textbf{Path transformation}\\
Let a graph $\gve$. By identifying vertices with paths of length $1$, a path $g \in \cp(G)$ can act as a transformation on $v \in V$ through the composition law of $\cp(G)$. Also note that $g(v) = g(v^{-1})$.
\end{claim}

We can nom define the $k$-Groupoid convolution operator on $\cs(G)$ by restriction of the second operand from $\cs(\Gamma)$ to paths of length $1$:

\begin{definition}\textbf{$k$-Groupoid convolution operator}\\
Let a graph $\gve$. Let a subgroupoid $\Gamma \subseteq \cp_k(G)$. The $k$-groupoid convolution operator $f_w$ with parameter $w \in \cs(\Gamma)$ is defined as:
\begin{gather*}
\forall s \in \cs(\Gamma), \forall h \in \Gamma, f_w(s)[h] = (s \ast w)[h]
\end{gather*}
And when restricted to $\cs(G)$ it is defined as:
\begin{gather*}
\forall s \in \cs(G), \forall v \in V, f_w(s)[v] = \displaystyle \sum_{\substack{g \in \Gamma\\ \st \psi(g) = v}} s[g(v)] \h{2} w[g]\\
\forall s \in \cs(G), \forall v \in V, f_w(s)[v] = \displaystyle \sum_{\substack{g \in \Gamma\\ \st \varphi(g) = v}} s[g] \h{2} w[g^{-1}(v)]
\end{gather*}
\end{definition}

\begin{proposition}\textbf{Groupoid equivariance to $\Gamma$}\\
$k$-Groupoid convolution operators on $\cs(G)$ are groupoid equivariant to $\Gamma$ \ie
\begin{gather*}
\exists w \in \cs(\Gamma), f = w \ast . \Rightarrow
\forall v \in V, \forall g \in \Gamma \st \psi(g^{-1}) = v,
f \circ g [v]= g \circ f [v]
\end{gather*}
\label{prop:equi}
\end{proposition}

\begin{gather}
g(h(v)) maybe false
\end{gather}




Mini patron of todo:
\begin{itemize}
\item Equivariance to $\Gamma$ holds, proof
\item Converse of characterization does not hold yet, except on orbits
\item property for it to hold
\item relaxing one-to-one correspondence constraint but keeping other properties
\item other avenue instead of property: should make use of edges to build a group structure
\item ideal graph (lattice-regular)
\item if group is too much then just groupoid structure from edges is enough
\end{itemize}

\todo{finish this section}

\subsection{To rename}

% \begin{definition}\textbf{Infinite graph}\\
% An \emph{infinite graph} is defined by natural extension of the notion of graph $G=\langle V,E \rangle$ where $V$ and $E$ can be infinite. We denote $\order{G} = \infty$.
% \end{definition}

\begin{definition}\textbf{Graph automorphisms}\\
A graph automorphism of a graph $\gve$ is a bijection in the vertex domain $\phi: V \rightarrow V$ such that $\{u,v\} \in E \Leftrightarrow \{\phi(u), \phi(v)\} \in E$. We denote $\ca(G)$ the group of automorphism on $G$.

We denote by $\ce(\phi)$ the set of input-output mapping of $\phi$, defined as $\ce(\phi) = \{ (x,y) \in V^2, \phi(x) = y \}$.

A graph automorphism $\phi$ is said to be \emph{edge-constrained} (EC) if $\ce(\phi) \subseteq E$. We denote $\ca_{\EC}(G)$ the set of edge-constrained automorphism on $G$.
\end{definition}

\begin{definition}\textbf{Orthogonality}\\
Two graph automorphisms $\phi_1$ and $\phi_2$ are said to be orthogonal, if and only if $\ce(\phi_1) \cap \ce(\phi_2) = \emptyset$, denoted $\phi_1 \bot \phi_2$. They are said to be aligned otherwise.

Similarly, we define orthogonality of $r$ automophisms as $\phi_1 \bot \cdots \bot \phi_r \Leftrightarrow \ce(\phi_1) \cap \cdots \cap \ce(\phi_r) = \emptyset$
\end{definition}


\subsection{Lattice-regular graph}

\begin{definition}\textbf{Lattice-regular graph}\\
A lattice-regular graph is a regular graph that admits $r$ orthogonal edge-constrained automorphisms, where $r$ is its degree.
\end{definition}


%\subsubsection{Grids}{}

%\subsubsection{Lattices}

%\subsubsection{Spatial graphs}

%\subsubsection{Projections of spatial graphs}
