\section{Convolutions on graphs (draft)}

Defining a convolution on graphs is a challenging problem. Obviously, the underlying structure determined by a graph is not necessarily isomorphic to a set onto which the convolution is already defined. 

Related works: moura, spectral convolution with laplacian.

A convolution may comprise the following properties: bilinear, equivariant with respect to a certain class of isomorphism.

We shall first study classes of graphs onto which the convolution can be naturally defined before generalizing.

*Convolution without the edges

*Convolution on grids

*Convolution on lattice-regular graphs

*Convolution on product graphs

*Convolution on linear combination of circulant graphs

\todo{brief outline}

\subsection{Analysis of the classical convolution operator}

In this subsection, we are exposing a few properties of the classical convolution that a generalization to graphs would likely try to preserve. For now let's consider a graph $G$ agnostically of its edges \ie $G \cong V$ is just the set of its vertices.

Let's recall what is a transformation, and how it acts on signals.

\begin{definition}\textbf{Transformation}\\
A \emph{transformation} $f: V \rightarrow V$ is a function with same domain and codomain. The set of transformations is denoted $\Phi(V)$. The set of bijective transformations is denoted $\Phi^*(V) \subset \Phi(V)$.

In case $f \in \Phi^*(V)$, it can act on $\cs(V)$ through the linear operator $L_f \in \cl(\cs(V))$ defined as:
\begin{gather*}
\forall s \in \cs(V), \forall v \in V, f(s)[v] := L_f s[v] = s[f^{-1}(v)]
\end{gather*}
\ie an entry of a transformed signal is obtained by doing a lookup of the entry of the original signal.

In case $f \notin \Phi^*(V)$, we can still define $L_f \in \cl(\cs(V))$, however we need to linearly aggregate the entries on the fibers:
\begin{gather*}
\forall s \in \cs(V), \forall v \in V, f(s)[v] := L_f s[v] = \agg\{s[u], u \in f^{-1}\{v\}\}
\end{gather*}
where $\agg$ can be for example the sum, the average, or the max, and $\agg(\emptyset) = 0$.
\end{definition}

\subsubsection{Characterization on grid graphs}

Consider an edge-less grid graph \ie $G \cong \bbz^2$. By restriction to compactly supported signals, this case encompass the case of images.

\begin{definition}\textbf{Translation on $\cs(\bbz^2)$}\\
A translation on $\bbz^2$ is defined as a transformation $t \in \Phi^*(\bbz^2)$ such that
\begin{gather*}
\exists (a,b) \in \bbz^2, \forall (x,y) \in \bbz^2, t(x,y) = (x+a,y+b)
\end{gather*}
It also acts on $\cs(\bbz^2)$ with the notation $t_{a,b}$ \ie
\begin{gather*}
\forall s \in \cs(\bbz^2), \forall (x,y) \in \bbz^2, t_{a,b}(s)[x,y] = s[x-a, y-b]
\end{gather*}
For any set $E$, we denote by $\ct(E)$ its translations if they are defined.
\end{definition}

\begin{definition}\textbf{Convolution on $\cs(\bbz^2)$}\\
Recall that the convolution between two signals $s_1$ and $s_2$ over $\bbz^2$ is a binary operator in $\cs(\bbz^2)$ defined as:
\begin{align*}
\forall (a,b) \in \bbz^2, (s_1 * s_2) [a,b] & = \displaystyle \sum_i \sum_j s_1[i,j] \h{2} s_2[a-i, b-j]
\end{align*}
\end{definition}

The next proposition can be seen as a discretization of a classic result in distribution theory.

\begin{proposition}\textbf{Characterization of convolution operators on $\cs(\bbz^2)$}\\
On real-valued signals over $\bbz^2$, the class of linear transformations that are equivariant to translations is exactly the class of convolutive operations \ie
\begin{gather*}
\exists w \in \cs(\bbz^2), f = . \ast w \Leftrightarrow
\begin{cases}
 f \in \cl(\cs(\bbz^2))\\
 \forall t \in \ct(\cs(\bbz^2)), f \circ t = t \circ f
\end{cases}
\end{gather*}
\label{prop:equi}
\end{proposition}

\begin{proof}
The result from left to right is a direct consequence of the definitions:
\begin{align}
\forall s \in \cs(\bbz^2), \forall s' \in \cs(\bbz^2), & \forall (\alpha, \beta) \in \bbr^2,\forall (a,b) \in \bbz^2,\nonumber\\
 %f_w(s)[a,b] & = \displaystyle \sum_i \sum_j s[i,j] \h{2} w[a-i, b-j] \tag{definition}\\
 f_w(\alpha s + \beta s')[a,b] & = \displaystyle \sum_i \sum_j (\alpha s + \beta s')[i,j] \h{2} w[a-i, b-j]\nonumber\\
 & = \alpha f_w(s)[a,b] + \beta f_w(s')[a,b] \tag{linearity}\\
\forall s \in \cs(\bbz^2), \forall (\alpha, \beta) \in \bbz^2, & \forall (a,b) \in \bbz^2,\nonumber\\
f_w \circ t_{\alpha,\beta} (s)[a,b] & = \displaystyle \sum_i \sum_j t_{\alpha,\beta}(s)[i,j] \h{2} w[a-i, b-j]\nonumber\\
 & = \displaystyle \sum_i \sum_j s[i - \alpha,j - \beta] \h{2} w[a-i, b-j]\nonumber\\
 & = \displaystyle \sum_{i'} \sum_{j'} s[i',j'] \h{2} w[a - i' - \alpha, b - j'- \beta]\label{eq:bij}\\
 & = f_w (s)[a - \alpha,b - \beta]\nonumber\\
 & = t_{\alpha,\beta} \circ f_w (s)[a,b] \tag{equivariance}
\end{align}
Now let's prove the result from right to left .

Let $f \in \cl(\cs(\bbz^2))$, $s \in \cs(\bbz^2)$. We suppose that $f$ commutes with translations. Recall that $s$ can be linearly decomposed on the infinite family of dirac signals:
\begin{gather*}
s = \displaystyle \sum_i \sum_j s[i,j] \h{2} \delta_{i,j} \text{, where }
\delta_{i,j}[x,y] = \begin{cases} 1 & \text{if } (x,y) = (i,j)\\ 0 & \text{otherwise} \end{cases}
\end{gather*}
By linearity of $f$ and then equivariance to translations:
\begin{align*}
f(s) & = \displaystyle \sum_i \sum_j s[i,j] \h{2} f(\delta_{i,j})\\
 & = \displaystyle \sum_i \sum_j s[i,j] \h{2} f \circ t_{i,j} (\delta_{0,0})\\
 & = \displaystyle \sum_i \sum_j s[i,j] \h{2} t_{i,j} \circ f (\delta_{0,0})
\end{align*}
By denoting $w = f (\delta_{0,0}) \in \cs(\bbz^2)$, we obtain:
\begin{align}
\forall (a,b) \in \bbz^2, f(s)[a,b] & = \displaystyle \sum_i \sum_j s[i,j] \h{2} t_{i,j}(w)[a,b] \label{eq:conv}\\
 & = \displaystyle \sum_i \sum_j s[i,j] \h{2} w[a-i, b-j] \nonumber\\
\text{\ie } f(s) & = s \ast w \nonumber
\end{align}
\end{proof}

\begin{remark}\textbf{Equivariance property of CNNs}\\
In deep learning, an important argument in favor of CNNs is that convolutional layers are equivariant to translations. Intuitively, that means that a detail of an object in an image should produce the same features independently of its position in the image.
\end{remark}

\begin{remark}\textbf{Lossless superiority of CNNs over MLPs}\\
The converse result, as a consequence of~\propref{prop:equi}, is never mentioned in deep learning literature. However it is also a strong one: it means that layers of CNNs have every translational equivariant functions in their search space, so it implies that the reduction of parameters from an MLP to a CNN is done with strictly no loss of expressivity (provided the objective function is know to bear this property). Besides, it helps the training to search in a much more confined space.
\end{remark}

\subsubsection{Construction on groups}

As \propref{prop:equi} is a complete characterization of convolutions, it can be used to define them \ie convolutive operations can be constructed as the set of linear transformations that are equivariant to translations. However, in the general case where $G$ is not a grid graph, translations are not defined, so that construction needs to be generalized beyond translational equivariances.

\todo{reword sentence below (not exactly true)}
A classic result from group theory is that one sense of this characterization (equivariance) hold for groups of (bijective) transformations, where the group of translations is a particular case. More generally, it also holds for groupoids \citep{weinstein1996groupoids}. The converse sense will be discussed later.

Note that our approach is different than in \citep{cohen2016group}, where the authors define group-equivariant convolutions from an already defined one. On graphs, convolutions aren't already defined. We are studying group convolutions in view of constructing one.

\begin{definition}\textbf{Group convolution I}\\
Let a group $\group$, the group convolution between two signals $s_1$ and $s_2 \in \cs(\group)$ is defined as:
\begin{align*}
\forall h \in \group, (s_1 \ast s_2)[h] & = \displaystyle \sum_{g \in \group} s_1[g] \h{2} s_2[g^{-1}h]%\\
%& = \displaystyle \sum_{ab = h} s_1[a] \h{2} s_2[b]
\end{align*}
provided one of the signals has finite support if $\group$ is not finite.
\label{def:conv1}
\end{definition}

For a graph $\gve$ and a subgroup $\Gamma \subset \Phi^*(V)$, this definition is applicable for $\cs(\Gamma)$, but not for $\cs(V)$ as $V$ is not a group.

Nonetheless, let's assume we can provide $V$ with a group structure by exhibiting an isomorphism $\varphi$ from $\Gamma$ to $V$. Then, the linear morphism $\widetilde\varphi$ from $\cs(\Gamma)$ to $\cs(V)$ defined by $\widetilde\varphi(\delta_g) = \delta_{\varphi(g)}$ is also an isomorphism. Hence, $V$ and $\cs(V)$ would inherit the same inherent structural properties as $\Gamma$ and $\cs(\Gamma)$, in addition of being related in the same way. For notational simplicity, we will use the same symbol $\varphi$ for $\varphi$ and $\widetilde\varphi$ (as done between $f$ and $L_f$). A Commutative diagram between the sets is depicted on \figref{fig:iso}.

\begin{figure}[H]
\centering
\begin{tikzcd}%
    \Gamma \arrow{r}{\varphi}  \arrow{d}[swap]{\cs}  & V \arrow{d}{\cs}\\  
    \cs(\Gamma) \arrow{r}[swap]{\varphi}  & \cs(V) 
\end{tikzcd}%
\caption{Commutative diagram}
\label{fig:iso}
\end{figure}

Hence, we can define the group convolution as follows:

\begin{definition}\textbf{Group convolution II}\\
Let $\Gamma \subset \Phi^*(V)$ such that $V \cong \Gamma$ through an isomorphism $g_v \overset{\varphi}\mapsto v$.
The group convolution between two signals $s_1$ and $s_2 \in \cs(V)$ is defined as:
\begin{align*}
\forall u \in V, (s_1 \ast s_2) [u] & = \displaystyle \sum_{v \in V} s_1[v] \h{2} s_2[\varphi(g_v^{-1}g_u)]\\
& = \displaystyle \sum_{\substack{(a,b) \in V^2 \\ \st g_ag_b=g_u }} s_1[a] \h{2} s_2[b]
\end{align*}
\label{def:conv2}
\end{definition}

\begin{proposition}\textbf{Equivariance to $\varphi(\Gamma)$}\\
With \defref{def:conv2}, convolution operators on $\cs(V)$ are equivariant to $\varphi(\Gamma)$ \ie
\begin{gather*}
\exists w \in \cs(V), f = . \ast w \Rightarrow \forall v \in V, f \circ \varphi(g_v) = \varphi(g_v) \circ f
\end{gather*}
\label{prop:equi}
\end{proposition}

\begin{proof}
\begin{align*}
\forall s \in \cs(V), \forall u \in V & ,\forall v \in V,\\
f_w \circ \varphi(g_u) (s) [v] & = \sum_{\substack{(a,b) \in V^2 \\ \st g_ag_b=g_v }} \varphi(g_u)(s)[a] \h{2} w[b]\\
& = \sum_{\substack{(a,b) \in V^2 \\ \st g_ag_b=g_v }} s[\varphi(g_u)^{-1}(a)] \h{2} w[b]\\
& = \sum_{\substack{(a,b) \in V^2 \\ \st g_{\varphi(g_u)(a)}g_b=g_v }} s[a] \h{2} w[b]\\
\end{align*}
Because $\varphi$ is an isomorphism, its inverse $c \mapsto g_c$ is also an isomorphism and so $g_{\varphi(g_u)(a)}g_b=g_v \Leftrightarrow g_{a}g_b=g_{\varphi(g_u)^{-1}(v)}$. So we have:
\begin{align*}
f_w \circ \varphi(g_u) (s) [v] & = \sum_{\substack{(a,b) \in V^2 \\ \st g_{a}g_b=g_{\varphi(g_u)^{-1}(v)} }} s[a] \h{2} w[b]\\
& = s \ast w [\varphi(g_u)^{-1}(v)]\\
& = g_u \circ f_w (s) [v]
\end{align*}
\end{proof}

In fact, both group convolutions are the same as the latter one borrows the algebraic structure of the first one, regardless of the fact that the group $\Gamma$ contains bijective transformations of $V$. We can exploit this fact to obtain equivariance to $\Gamma$ for both (instead of only to $\varphi(\Gamma)$ for the latter). By noticing that $g \in \Gamma$ can act on both $\cs(\Gamma)$ through the linear transformation of the left multiplication and on $\cs(V)$ as being an object of $\Phi^{*}(V)$, we define:

\begin{definition}\textbf{Group convolution III}\\
Let $\Gamma \subset \Phi^*(V)$ such that $V \cong \Gamma$ through an isomorphism $g_v \overset{\varphi}\mapsto v$ which verifies the property: $$\forall v \in V, \forall u \in V, g_v(u) = \varphi(g_vg_u)$$
The group convolution between two signals $s_1$ and $s_2 \in \cs(V)$ is defined as:
\begin{align*}
\forall u \in V, (s_1 \ast s_2) [u] & = \displaystyle \sum_{v \in V} s_1[v] \h{2} s_2[\varphi(g_v^{-1}g_u)]\\
& = \displaystyle \sum_{v \in V} s_1[v] \h{2} s_2[g_v^{-1}(u)]\\
\ie s_1 \ast s_2 & = \displaystyle \sum_{v \in V} s_1[v] \h{2} g_v(s_2)\\
& = \displaystyle \sum_{g \in \Gamma} s_1[\varphi(g)] \h{2} g(s_2) %This one is to use latter
\end{align*}
\label{def:conv3}
\end{definition}

\begin{remark}
For example, this property holds for translations as $t_{i,j}(a,b) = \varphi(t_{i,j} \circ t_{a,b})$ (with $\varphi(t_{i,j}) = (i,j)$).
\end{remark}

\begin{proposition}\textbf{Equivariance to $\Gamma$}\\
With \defref{def:conv3}, convolution operators on $\cs(V)$ are equivariant to $\Gamma$ \ie
\begin{gather*}
\exists w \in \cs(V), f = . \ast w \Rightarrow \forall v \in V, f \circ g_v = g_v \circ f
\end{gather*}
\label{prop:equi}
\end{proposition}

\begin{proof}
In the following equations, \eqref{eq:left} is obtained because left multiplication in a group is an isomorphism, and \eqref{eq:pty} is obtained from the property of \defref{def:conv3}.
\begin{align}
\forall g \in \Gamma, \forall s \in \cs(V), & \nonumber\\
f_w \circ g (s) & = \displaystyle \sum_{h \in \Gamma} g(s)[\varphi(h)] \h{2} h(w)\nonumber\\
 & = \displaystyle \sum_{h \in \Gamma} g(s)[\varphi(gh)] \h{2} gh(w)\label{eq:left}\\
 & = \displaystyle \sum_{h \in \Gamma} g(s)[g(\varphi(h))] \h{2} gh(w)\label{eq:pty}\\
 & = \displaystyle \sum_{h \in \Gamma} s[\varphi(h)] \h{2} gh(w)\nonumber\\
\forall g \in \Gamma, \forall s \in \cs(V), & \forall u \in V, \nonumber\\
f_w \circ g (s) [u] & = \displaystyle \sum_{h \in \Gamma} s[\varphi(h)] \h{2} h(w)[g^{-1}(u)]\nonumber\\
& = f_w (s) [g^{-1}(u)]\nonumber\\
& = g \circ f_w (s) [u]\nonumber
\end{align}
\end{proof}

At this point we might finally want to consider the edge set.

\subsubsection{Construction on graph groupoids}

On graphs, we notice that the property $g(u) = \varphi(gh)$ can be realized by transformations defined on edges. The following definitions clarify our discussion.

\begin{definition}\textbf{Graph groupoid}\\
The \emph{groupoid} of a graph \gve is the set of ordered pairs of connected vertices equiped with:
\begin{itemize}
\item a map $\psi: (u,v) \mapsto u$ and another map $\varphi: (u,v) \mapsto v$
\item a closed composition law $gh = (\psi(g),\varphi(h))$ defined on $\{(g,h), \varphi(g) = \psi(h)\}$
\end{itemize}

\end{definition}



% $$
% \displaystyle \sum_{g \in \Gamma} s_1[\varphi(g)] \h{2} g(s_2)
% $$


%Armed with the last definition, let's consider a graph \vge. 






Mini patron:
\begin{itemize}
\item Equivariance to $\Gamma$ holds, proof
\item Converse of characterization does not hold yet, except on orbits
\item property for it to hold
\item relaxing one-to-one correspondence constraint but keeping other properties
\item other avenue instead of property: should make use of edges to build a group structure
\item ideal graph (lattice-regular)
\item if group is too much then just groupoid structure from edges is enough
\end{itemize}

\todo{finish this section}

\subsection{To rename}

% \begin{definition}\textbf{Infinite graph}\\
% An \emph{infinite graph} is defined by natural extension of the notion of graph $G=\langle V,E \rangle$ where $V$ and $E$ can be infinite. We denote $\order{G} = \infty$.
% \end{definition}

\begin{definition}\textbf{Graph automorphisms}\\
A graph automorphism of a graph $\gve$ is a bijection in the vertex domain $\phi: V \rightarrow V$ such that $\{u,v\} \in E \Leftrightarrow \{\phi(u), \phi(v)\} \in E$. We denote $\ca(G)$ the group of automorphism on $G$.

We denote by $\ce(\phi)$ the set of input-output mapping of $\phi$, defined as $\ce(\phi) = \{ (x,y) \in V^2, \phi(x) = y \}$.

A graph automorphism $\phi$ is said to be \emph{edge-constrained} (EC) if $\ce(\phi) \subseteq E$. We denote $\ca_{\EC}(G)$ the set of edge-constrained automorphism on $G$.
\end{definition}

\begin{definition}\textbf{Orthogonality}\\
Two graph automorphisms $\phi_1$ and $\phi_2$ are said to be orthogonal, if and only if $\ce(\phi_1) \cap \ce(\phi_2) = \emptyset$, denoted $\phi_1 \bot \phi_2$. They are said to be aligned otherwise.

Similarly, we define orthogonality of $r$ automophisms as $\phi_1 \bot \cdots \bot \phi_r \Leftrightarrow \ce(\phi_1) \cap \cdots \cap \ce(\phi_r) = \emptyset$
\end{definition}


\subsection{Lattice-regular graph}

\begin{definition}\textbf{Lattice-regular graph}\\
A lattice-regular graph is a regular graph that admits $r$ orthogonal edge-constrained automorphisms, where $r$ is its degree.
\end{definition}


%\subsubsection{Grids}{}

%\subsubsection{Lattices}

%\subsubsection{Spatial graphs}

%\subsubsection{Projections of spatial graphs}
