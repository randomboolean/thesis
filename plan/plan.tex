\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}

\newcommand{\fakesection}[1]{%
  \par\refstepcounter{section}% Increase section counter
  \sectionmark{#1}% Add section mark (header)
  \addcontentsline{toc}{section}{\protect\numberline{\thesection}#1}% Add section to ToC
  % Add more content here, if needed.
}

\newcommand{\fakesubsection}[1]{%
  \par\refstepcounter{subsection}% Increase subsection counter
  \subsectionmark{#1}% Add subsection mark (header)
  \addcontentsline{toc}{subsection}{\protect\numberline{\thesubsection}#1}% Add subsection to ToC
  % Add more content here, if needed.
}

\newcommand{\keywords}[1]{\textbf{\textit{Index terms---}} #1}

\begin{document}

\fakesection{Introduction}
\fakesubsection{Plan, vision, etc}
\fakesubsection{Deep learning and history}
\fakesubsection{Regular deep learning}
\fakesubsection{Irregular deep learning}
\fakesubsection{Unstructured deep learning}
\fakesubsection{Propagational point of view}

\fakesection{Presentation of the domain}
\fakesubsection{Typology of data}
\fakesubsection{Standardized terminology}
\fakesubsection{Motivation}
\fakesubsection{Datasets}
\fakesubsection{Unifying framework (tensorial product)}
\fakesubsection{Other Unifying frameworks}

\fakesection{Review of models and propositions}
\fakesubsection{How to compare models}
\fakesubsection{Spectral models}
\fakesubsection{Non-spectral}
\fakesubsection{Non-convolutional}
%\fakesubsection{Our models I}
%\fakesubsection{Our models II}
\fakesubsection{Recap and (big) comparison table}
\fakesubsection{Explaining current SOA, current issues, and further work}

\fakesection{Transposing the problem formulation: Structural learning}
\fakesubsection{Structural Representation}
\fakesubsection{Feature visualization (viz on input)}
\fakesubsection{Propagated Signal visualization (viz on S)}
\fakesubsection{Temptatives on learning S}
\fakesubsection{Temptatives on learning S (other)}
\fakesubsection{Covariance-based convolution}
\fakesubsection{Conclusion}

\fakesection{Industrial applications}
\fakesubsection{Context}
\fakesubsection{The Warp 10 platform and Warpscript language}
\fakesubsection{Presentation of use cases: uni vs multi-variate, spatial vs geo, etc ..}
\fakesubsection{Review and application on regularly structured (spatial) time series}
\fakesubsection{Application to time series database (unstructured)}
\fakesubsection{Application to geo time series (unstructured)}
\fakesubsection{Application to visualization}
\fakesubsection{Market reality (what clients need, what they don't know that can be done ...)}
\fakesubsection{Conclusion}

\fakesection{Conclusion}
\fakesubsection{Summary}
\fakesubsection{Lesson learned}
\fakesubsection{Further avenues}

\tableofcontents

\hfill

\begin{keywords}
Deep learning, representation learning, propagation learning, visualization, structured, unstructured regular, irregular,
covariant, invariant, equivariant, tensor, scheme, weight sharing, graphs, manifold, euclidean, signal processing, graph signal processing,  time series, time series database, distributed application, spatial-time series, geo time series, industrial applications, warp 10, warpscript, ...
\end{keywords}


\section*{Temptative titles}
\begin{itemize}
\item Learning propagational representations of irregular and unstructured data
\item Learning representations of unstructured or irregularly structured datasets
\item Propagational learning of unstructured or irregularly structured datasets
\item Learning tensorial representation of irregular and unstructured data
\item Tensorial representation of propagation in deep learning for irregular and unstructured dataset
\item Structural representation learning for irregular or unstructured data
\item Word for both ``irregularly structured'' + ``unstructured'' = ? (maybe ``unorthodox'' ?)
\item Unorthdox deep learning
\item ...
\item Deep learning of unstructured or irregularly structured datasets
\end{itemize}

\end{document}